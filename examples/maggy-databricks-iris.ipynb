{"cells":[{"cell_type":"markdown","source":["d\nMaggy enables you to train with Tensorflow distributed optimizers.\nUsing Maggy, you have to make minimal changes in train your model in a distributed fashion."],"metadata":{"pycharm":{"name":"#%% md\n"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f335f45-d61f-4341-b9eb-993b5743a2cb"}}},{"cell_type":"markdown","source":["### 0. Spark Session\n\nMake sure you have a running Spark Session/Context available.\n\nOn Hopsworks, just run your notebook to start the spark application.\n\n### 1. Model definition\n\nLet's define the model we want to train. The layers of the model have to be defined in the \\_\\_init__ function.\n\nDo not instantiate the class, otherwise you won't be able to use Maggy."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd1d717a-dce6-48fc-b33c-b62ee62bf262"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nimport os\n\ntry:\n  import tensorflow as tf\nexcept ModuleNotFoundError:\n  %pip install tensorflow-cpu==2.4.1\n"],"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d102ab8-36dc-4f4d-9442-9e493af2d523"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import tensorflow as tf\nif tf.__version__ != '2.4.1':\n  %pip install tensorflow-cpu==2.4.1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17b233a3-1b0f-470d-8e39-579b238efb47"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting tensorflow-cpu==2.4.1\n  Downloading tensorflow_cpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (144.1 MB)\nCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: google-pasta~=0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (0.2.0)\nCollecting six~=1.15.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nRequirement already satisfied: opt-einsum~=3.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.3.0)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\nCollecting tensorboard~=2.4\n  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\nCollecting tensorflow-estimator&lt;2.5.0,&gt;=2.4.0\n  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\nRequirement already satisfied: termcolor~=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.1.0)\nCollecting grpcio~=1.32.0\n  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\nRequirement already satisfied: typing-extensions~=3.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.7.4.3)\nCollecting wheel~=0.35\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nRequirement already satisfied: protobuf&gt;=3.9.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.11.4)\nRequirement already satisfied: h5py~=2.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (2.10.0)\nRequirement already satisfied: astunparse~=1.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.6.3)\nCollecting wrapt~=1.12.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting absl-py~=0.10\n  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\nRequirement already satisfied: gast==0.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (0.3.3)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.1.2)\nCollecting tensorboard-data-server&lt;0.7.0,&gt;=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\nRequirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.4.1)\nRequirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.7.0)\nRequirement already satisfied: requests&lt;3,&gt;=2.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2.22.0)\nRequirement already satisfied: markdown&gt;=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.1.1)\nRequirement already satisfied: setuptools&gt;=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (45.2.0.post20200210)\nRequirement already satisfied: werkzeug&gt;=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.0.0)\nRequirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.11.2)\nRequirement already satisfied: requests-oauthlib&gt;=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.3.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.25.8)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2.8)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2020.11.8)\nRequirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (4.1.1)\nRequirement already satisfied: rsa&lt;4.1,&gt;=3.1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (4.0)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.2.8)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.1.0)\nRequirement already satisfied: pyasn1&gt;=0.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from rsa&lt;4.1,&gt;=3.1.4-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.4.8)\nBuilding wheels for collected packages: wrapt\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=71061 sha256=ac680c5d28e6d70a9a062d64b2f921a7c59b85ba2b77ddcaa40b30dc65be3668\n  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built wrapt\nERROR: torch 1.7.0 requires dataclasses, which is not installed.\nERROR: petastorm 0.9.7 requires pyspark&gt;=2.1.0, which is not installed.\nERROR: mlflow 1.12.1 requires alembic&lt;=1.4.1, which is not installed.\nERROR: mlflow 1.12.1 requires prometheus-flask-exporter, which is not installed.\nERROR: mlflow 1.12.1 requires sqlalchemy, which is not installed.\nERROR: maggy 0.5.0 has requirement numpy==1.20.1, but you&#39;ll have numpy 1.19.5 which is incompatible.\nInstalling collected packages: flatbuffers, six, numpy, tensorboard-data-server, absl-py, wheel, grpcio, tensorboard, tensorflow-estimator, wrapt, tensorflow-cpu\n  Attempting uninstall: six\n    Found existing installation: six 1.14.0\n    Uninstalling six-1.14.0:\n      Successfully uninstalled six-1.14.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.20.1\n    Uninstalling numpy-1.20.1:\n      Successfully uninstalled numpy-1.20.1\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.9.0\n    Uninstalling absl-py-0.9.0:\n      Successfully uninstalled absl-py-0.9.0\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.34.2\n    Uninstalling wheel-0.34.2:\n      Successfully uninstalled wheel-0.34.2\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.27.2\n    Uninstalling grpcio-1.27.2:\n      Successfully uninstalled grpcio-1.27.2\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.3.0\n    Uninstalling tensorboard-2.3.0:\n      Successfully uninstalled tensorboard-2.3.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.3.0\n    Uninstalling tensorflow-estimator-2.3.0:\n      Successfully uninstalled tensorflow-estimator-2.3.0\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.11.2\n    Uninstalling wrapt-1.11.2:\n      Successfully uninstalled wrapt-1.11.2\n  Attempting uninstall: tensorflow-cpu\n    Found existing installation: tensorflow-cpu 2.3.1\n    Uninstalling tensorflow-cpu-2.3.1:\n      Successfully uninstalled tensorflow-cpu-2.3.1\nSuccessfully installed absl-py-0.12.0 flatbuffers-1.12 grpcio-1.32.0 numpy-1.19.5 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-cpu-2.4.1 tensorflow-estimator-2.4.0 wheel-0.36.2 wrapt-1.12.1\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting tensorflow-cpu==2.4.1\n  Downloading tensorflow_cpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (144.1 MB)\nCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: google-pasta~=0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (0.2.0)\nCollecting six~=1.15.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nRequirement already satisfied: opt-einsum~=3.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.3.0)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\nCollecting tensorboard~=2.4\n  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\nCollecting tensorflow-estimator&lt;2.5.0,&gt;=2.4.0\n  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\nRequirement already satisfied: termcolor~=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.1.0)\nCollecting grpcio~=1.32.0\n  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\nRequirement already satisfied: typing-extensions~=3.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.7.4.3)\nCollecting wheel~=0.35\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nRequirement already satisfied: protobuf&gt;=3.9.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (3.11.4)\nRequirement already satisfied: h5py~=2.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (2.10.0)\nRequirement already satisfied: astunparse~=1.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.6.3)\nCollecting wrapt~=1.12.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting absl-py~=0.10\n  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\nRequirement already satisfied: gast==0.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (0.3.3)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorflow-cpu==2.4.1) (1.1.2)\nCollecting tensorboard-data-server&lt;0.7.0,&gt;=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\nRequirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.4.1)\nRequirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.7.0)\nRequirement already satisfied: requests&lt;3,&gt;=2.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2.22.0)\nRequirement already satisfied: markdown&gt;=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.1.1)\nRequirement already satisfied: setuptools&gt;=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (45.2.0.post20200210)\nRequirement already satisfied: werkzeug&gt;=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.0.0)\nRequirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.11.2)\nRequirement already satisfied: requests-oauthlib&gt;=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.3.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (1.25.8)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2.8)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (2020.11.8)\nRequirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (4.1.1)\nRequirement already satisfied: rsa&lt;4.1,&gt;=3.1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (4.0)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.2.8)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (3.1.0)\nRequirement already satisfied: pyasn1&gt;=0.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54e0165f-adde-4c2b-970a-ef83f9b4563a/lib/python3.7/site-packages (from rsa&lt;4.1,&gt;=3.1.4-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow-cpu==2.4.1) (0.4.8)\nBuilding wheels for collected packages: wrapt\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=71061 sha256=ac680c5d28e6d70a9a062d64b2f921a7c59b85ba2b77ddcaa40b30dc65be3668\n  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built wrapt\nERROR: torch 1.7.0 requires dataclasses, which is not installed.\nERROR: petastorm 0.9.7 requires pyspark&gt;=2.1.0, which is not installed.\nERROR: mlflow 1.12.1 requires alembic&lt;=1.4.1, which is not installed.\nERROR: mlflow 1.12.1 requires prometheus-flask-exporter, which is not installed.\nERROR: mlflow 1.12.1 requires sqlalchemy, which is not installed.\nERROR: maggy 0.5.0 has requirement numpy==1.20.1, but you&#39;ll have numpy 1.19.5 which is incompatible.\nInstalling collected packages: flatbuffers, six, numpy, tensorboard-data-server, absl-py, wheel, grpcio, tensorboard, tensorflow-estimator, wrapt, tensorflow-cpu\n  Attempting uninstall: six\n    Found existing installation: six 1.14.0\n    Uninstalling six-1.14.0:\n      Successfully uninstalled six-1.14.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.20.1\n    Uninstalling numpy-1.20.1:\n      Successfully uninstalled numpy-1.20.1\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.9.0\n    Uninstalling absl-py-0.9.0:\n      Successfully uninstalled absl-py-0.9.0\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.34.2\n    Uninstalling wheel-0.34.2:\n      Successfully uninstalled wheel-0.34.2\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.27.2\n    Uninstalling grpcio-1.27.2:\n      Successfully uninstalled grpcio-1.27.2\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.3.0\n    Uninstalling tensorboard-2.3.0:\n      Successfully uninstalled tensorboard-2.3.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.3.0\n    Uninstalling tensorflow-estimator-2.3.0:\n      Successfully uninstalled tensorflow-estimator-2.3.0\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.11.2\n    Uninstalling wrapt-1.11.2:\n      Successfully uninstalled wrapt-1.11.2\n  Attempting uninstall: tensorflow-cpu\n    Found existing installation: tensorflow-cpu 2.3.1\n    Uninstalling tensorflow-cpu-2.3.1:\n      Successfully uninstalled tensorflow-cpu-2.3.1\nSuccessfully installed absl-py-0.12.0 flatbuffers-1.12 grpcio-1.32.0 numpy-1.19.5 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-cpu-2.4.1 tensorflow-estimator-2.4.0 wheel-0.36.2 wrapt-1.12.1\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from tensorflow import keras \nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\n# you can use keras.Sequential(), you just need to override it \n# on a custom class and define the layers in __init__()\nclass NeuralNetwork(Sequential):\n        \n    def __init__(self, nl=4):\n        \n        super().__init__()\n        self.add(Dense(10,input_shape=(None,4),activation='tanh'))\n        if nl >= 4:\n          for i in range(0, nl-2):\n            self.add(Dense(8,activation='tanh'))\n        self.add(Dense(3,activation='softmax'))\n\nmodel = NeuralNetwork"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e86b1d9b-6989-4bc1-a5c9-377fae70b928"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 2. Dataset creation\n\nYou can create the dataset here and pass it to the TfDistributedConfig, or creating it in the training function.\n\nYou need to change the dataset path is correct."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddede077-fba9-4e02-bce0-b58076b9c7fb"}}},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/FileStore/tables/iris_train-2.csv\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b5fc0f6-29e0-4d7a-8bae-adef0c71d3d5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/FileStore/tables/iris_train-2.csv","iris_train-2.csv",3745]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/iris_train-2.csv</td><td>iris_train-2.csv</td><td>3745</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_set_path = \"dbfs:/FileStore/tables/iris_train-2.csv\"\ntest_set_path = \"dbfs:/FileStore/tables/iris_test-1.csv\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6d9d56a-32f1-4f3a-b1a2-75c9fb2fa799"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_set = spark.read.format(\"csv\").option(\"header\",\"true\")\\\n  .option(\"inferSchema\", \"true\").load(train_set_path).drop('_c0')\n\ntest_set = spark.read.format(\"csv\").option(\"header\",\"true\")\\\n  .option(\"inferSchema\", \"true\").load(test_set_path).drop('_c0')\n\nraw_train_set = train_set.toPandas().values\nraw_test_set = test_set.toPandas().values"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2be3e022-ce78-432a-b454-fadcab65cfbf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def process_data(train_set, test_set):\n    \n    import pandas as pd\n    import numpy as np\n    from sklearn.preprocessing import LabelEncoder\n    from sklearn.model_selection import train_test_split\n    \n    X_train = train_set[:,0:4]\n    y_train = train_set[:,4:]\n    X_test = test_set[:,0:4]\n    y_test = test_set[:,4:]\n\n    return (X_train, y_train), (X_test, y_test)\n  \ntrain_set, test_set = process_data(raw_train_set, raw_test_set)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9e43e01-48f9-40ec-9290-d2fc091958ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3. Defining the training function\n\nThe programming model is that you wrap the code containing the model training inside a wrapper function. Inside that wrapper function provide all imports and parts that make up your experiment.\n\nThe function should return the metric that you want to optimize for. This should coincide with the metric being reported in the Keras callback (see next point).\nYou can return the metric list, in this case only the loss element will be printed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75fd09d0-ae37-45ee-837d-5c509d96953c"}}},{"cell_type":"code","source":["def hpo_function(number_layers, reporter):\n  \n  model = NeuralNetwork(nl=number_layers)\n  model.build()\n  \n  #fitting the model and predicting\n  model.compile(Adam(lr=0.04),'categorical_crossentropy',metrics=['accuracy'])\n  train_input, test_input = process_data(raw_train_set, raw_test_set)\n\n  train_batch_size = 75\n  test_batch_size = 15\n  epochs = 10\n  \n  model.fit(x=train_input[0], y=train_input[1],\n            batch_size=train_batch_size,\n            epochs=epochs,\n            verbose=1)\n\n  score = model.evaluate(x=test_input[0], y=test_input[1], batch_size=test_batch_size, verbose=1)\n                         \n  print(f'Test loss: {score[0]}')\n  print(f'Test accuracy: {score[1]}')\n\n  return score[1]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31c9de50-b0fa-4c2e-a006-5789584c93ac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def training_function(model, train_set, test_set, hparams):\n    \n    model = model(nl=hparams['number_layers'])\n    model.build()\n    #fitting the model and predicting\n\n    model.compile(Adam(lr=hparams['learning_rate']),'categorical_crossentropy',metrics=['accuracy'])\n    \n    #raise ValueError(list(train_set.as_numpy_iterator()))\n\n    model.fit(train_set,epochs=hparams['epochs'])\n\n    accuracy = model.evaluate(test_set)\n\n    return accuracy"],"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0254c557-881c-4e8d-a419-a5a9c821cabd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 4. Configuring the experiment\n\nIn order to use maggy distributed training, we have to configure the training model, we can pass it to TfDistributedConfig.\nthe model class has to be an implementation of __tf.keras.Model__.\nWe can also define __train_set__, __test_set__ and eventually the __model_parameters__. __model_parameters__ is a dictionary\ncontaining the parameters to be used in the \\_\\_init__ function of your model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0dfba683-4762-46bb-8d24-ead06e0f10bf"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a18950e-4bce-4cf0-b279-850e079973ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from maggy.experiment_config import OptimizationConfig\nfrom maggy import Searchspace\n\n# The searchspace can be instantiated with parameters\nsp = Searchspace(number_layers=('INTEGER', [2, 8]))\n\nhpo_config = OptimizationConfig(num_trials=4, optimizer=\"randomsearch\", searchspace=sp, direction=\"max\", es_interval=1, es_min=5, name=\"hp_tuning_test\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40fa7892-a257-48be-92e7-49172d08ac5d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Hyperparameter added: number_layers\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Hyperparameter added: number_layers\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 5. Run distributed training\n\nFinally, we are ready to launch the maggy experiment. You just need to pass 2 parameters: the training function and the configuration variable we defined in the previous steps."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40a1c764-f4df-4b66-a666-587a85bfbe3b"}}},{"cell_type":"code","source":["from maggy import experiment\n\nresult = experiment.lagom(train_fn=hpo_function, config=hpo_config)\n\nprint(result)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8636a5d1-c330-4034-abbf-3a5e1417da95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\n------ RandomSearch Results ------ direction(max) \nBEST combination {&#34;number_layers&#34;: 3} -- metric 1.0\nWORST combination {&#34;number_layers&#34;: 7} -- metric 0.5666666626930237\nAVERAGE metric -- 0.8583333194255829\nEARLY STOPPED Trials -- 0\nTotal job time 0 hours, 0 minutes, 15 seconds\n\nFinished experiment.\n{&#39;best_id&#39;: &#39;0a1e587da4ba033b&#39;, &#39;best_val&#39;: 1.0, &#39;best_config&#39;: {&#39;number_layers&#39;: 3}, &#39;worst_id&#39;: &#39;882491b7850528b2&#39;, &#39;worst_val&#39;: 0.5666666626930237, &#39;worst_config&#39;: {&#39;number_layers&#39;: 7}, &#39;avg&#39;: 0.8583333194255829, &#39;metric_list&#39;: [0.8999999761581421, 0.5666666626930237, 1.0, 0.9666666388511658], &#39;num_trials&#39;: 4, &#39;early_stopped&#39;: 0, &#39;num_epochs&#39;: 0, &#39;trial_id&#39;: &#39;0a1e587da4ba033b&#39;}\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n------ RandomSearch Results ------ direction(max) \nBEST combination {&#34;number_layers&#34;: 3} -- metric 1.0\nWORST combination {&#34;number_layers&#34;: 7} -- metric 0.5666666626930237\nAVERAGE metric -- 0.8583333194255829\nEARLY STOPPED Trials -- 0\nTotal job time 0 hours, 0 minutes, 15 seconds\n\nFinished experiment.\n{&#39;best_id&#39;: &#39;0a1e587da4ba033b&#39;, &#39;best_val&#39;: 1.0, &#39;best_config&#39;: {&#39;number_layers&#39;: 3}, &#39;worst_id&#39;: &#39;882491b7850528b2&#39;, &#39;worst_val&#39;: 0.5666666626930237, &#39;worst_config&#39;: {&#39;number_layers&#39;: 7}, &#39;avg&#39;: 0.8583333194255829, &#39;metric_list&#39;: [0.8999999761581421, 0.5666666626930237, 1.0, 0.9666666388511658], &#39;num_trials&#39;: 4, &#39;early_stopped&#39;: 0, &#39;num_epochs&#39;: 0, &#39;trial_id&#39;: &#39;0a1e587da4ba033b&#39;}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from maggy.experiment_config.tf_distributed import TfDistributedConfig\n\n#define the constructor parameters of your model\nmodel_params = {\n    #train dataset entries / num_workers\n    'train_batch_size': 75,\n    #test dataset entries / num_workers\n    'test_batch_size': 15,\n    'learning_rate': 0.04,\n    'epochs': 20,\n    'number_layers': result['best_config']['number_layers'],\n}\n\ntraining_config = TfDistributedConfig(name=\"tf_test\", model=model, train_set=train_set, test_set=test_set, process_data=process_data, hparams = model_params)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7be5d4c5-8d62-4a16-b2a8-186dc9c088b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["experiment.lagom(training_function, training_config)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d47ecdb-4191-45a0-b6bd-251762af151e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Final average test loss: 0.178\nFinished experiment. Total run time: 0 hours, 0 minutes, 16 seconds\nOut[17]: {&#39;test result&#39;: 0.17838226817548275}</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Final average test loss: 0.178\nFinished experiment. Total run time: 0 hours, 0 minutes, 16 seconds\nOut[17]: {&#39;test result&#39;: 0.17838226817548275}</div>"]}}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pysparkkernel"},"language_info":{"codemirror_mode":{"name":"python","version":3},"mimetype":"text/x-python","name":"pyspark","pygments_lexer":"python3"},"application/vnd.databricks.v1+notebook":{"notebookName":"maggy-tf-dist-iris","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1415393082320837}},"nbformat":4,"nbformat_minor":0}
